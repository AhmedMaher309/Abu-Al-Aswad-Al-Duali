{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "import re\n",
    "import numpy as np\n",
    "from pyarabic.araby import separate, tokenize, is_arabicrange, strip_tashkeel, strip_tatweel\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading and writing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileReader:\n",
    "    \n",
    "    # write the data inside the file with file_name\n",
    "    def write_file(self,file_name, data):\n",
    "        if not os.path.exists(\"dataset\"):\n",
    "            os.makedirs(\"dataset\")\n",
    "        # Combine folder and file path\n",
    "        file_path = os.path.join(\"dataset\", file_name)\n",
    "        \n",
    "        # Write the cleaned data to a new text file\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(data)\n",
    "\n",
    "    # opne the file with file_name, extract the file data, and return it \n",
    "    def open_file(self, file_name):\n",
    "        file_path = os.path.join(\"dataset\", file_name)\n",
    "        f = open(file_path, 'r', encoding=\"utf-8\").read()\n",
    "        return f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data cleaning and processing utilities \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الذمي أن يحتسب على المسلم\n",
      "['', '', 'ِّ', 'ِّ', 'ِّ', '', 'َ', 'ْ', '', 'َ', 'ْ', 'َ', 'ِ', 'َ', '', 'َ', 'َ', '', '', '', 'ْ', 'ُ', 'ْ', 'ِ', '']\n",
      "Extracted Diacritic: No Diacritic\n",
      "Extracted Diacritic: No Diacritic\n",
      "Extracted Diacritic: SHADDA_KASRA\n",
      "Extracted Diacritic: SHADDA_KASRA\n",
      "Extracted Diacritic: SHADDA_KASRA\n",
      "Extracted Diacritic: No Diacritic\n",
      "Extracted Diacritic: FATHA\n",
      "Extracted Diacritic: SUKUN\n",
      "Extracted Diacritic: No Diacritic\n",
      "Extracted Diacritic: FATHA\n",
      "Extracted Diacritic: SUKUN\n",
      "Extracted Diacritic: FATHA\n",
      "Extracted Diacritic: KASRA\n",
      "Extracted Diacritic: FATHA\n",
      "Extracted Diacritic: No Diacritic\n",
      "Extracted Diacritic: FATHA\n",
      "Extracted Diacritic: FATHA\n",
      "Extracted Diacritic: No Diacritic\n",
      "Extracted Diacritic: No Diacritic\n",
      "Extracted Diacritic: No Diacritic\n",
      "Extracted Diacritic: SUKUN\n",
      "Extracted Diacritic: DAMMA\n",
      "Extracted Diacritic: SUKUN\n",
      "Extracted Diacritic: KASRA\n",
      "Extracted Diacritic: No Diacritic\n",
      "{(':', b':'), (\"'\", b\"'\"), (')', b')'), ('ن', b'\\xd9\\x86'), ('ى', b'\\xd9\\x89'), ('؟', b'\\xd8\\x9f'), ('ح', b'\\xd8\\xad'), ('َ', b'\\xd9\\x8e'), ('؛', b'\\xd8\\x9b'), ('ل', b'\\xd9\\x84'), ('9', b'9'), ('\\n', b'\\n'), ('–', b'\\xe2\\x80\\x93'), ('\\u200f', b'\\xe2\\x80\\x8f'), ('ة', b'\\xd8\\xa9'), ('.', b'.'), ('ج', b'\\xd8\\xac'), ('«', b'\\xc2\\xab'), ('ه', b'\\xd9\\x87'), ('`', b'`'), ('ٌ', b'\\xd9\\x8c'), ('1', b'1'), ('4', b'4'), ('ص', b'\\xd8\\xb5'), ('ُ', b'\\xd9\\x8f'), ('ع', b'\\xd8\\xb9'), ('غ', b'\\xd8\\xba'), ('(', b'('), ('[', b'['), ('إ', b'\\xd8\\xa5'), ('{', b'{'), ('ي', b'\\xd9\\x8a'), (']', b']'), ('ذ', b'\\xd8\\xb0'), (';', b';'), (',', b','), ('~', b'~'), ('د', b'\\xd8\\xaf'), ('ِ', b'\\xd9\\x90'), ('ف', b'\\xd9\\x81'), (' ', b' '), ('ئ', b'\\xd8\\xa6'), ('*', b'*'), ('ء', b'\\xd8\\xa1'), ('ت', b'\\xd8\\xaa'), ('م', b'\\xd9\\x85'), ('ق', b'\\xd9\\x82'), ('و', b'\\xd9\\x88'), ('8', b'8'), ('ْ', b'\\xd9\\x92'), ('!', b'!'), ('6', b'6'), ('ا', b'\\xd8\\xa7'), ('}', b'}'), ('ؤ', b'\\xd8\\xa4'), ('ر', b'\\xd8\\xb1'), ('5', b'5'), ('0', b'0'), ('\"', b'\"'), ('ً', b'\\xd9\\x8b'), ('ز', b'\\xd8\\xb2'), ('ك', b'\\xd9\\x83'), ('3', b'3'), ('»', b'\\xc2\\xbb'), ('ط', b'\\xd8\\xb7'), ('7', b'7'), ('آ', b'\\xd8\\xa2'), ('ٍ', b'\\xd9\\x8d'), ('أ', b'\\xd8\\xa3'), ('ّ', b'\\xd9\\x91'), ('س', b'\\xd8\\xb3'), ('ث', b'\\xd8\\xab'), ('ب', b'\\xd8\\xa8'), ('ض', b'\\xd8\\xb6'), ('-', b'-'), ('خ', b'\\xd8\\xae'), ('،', b'\\xd8\\x8c'), ('ش', b'\\xd8\\xb4'), ('/', b'/'), ('2', b'2'), ('ظ', b'\\xd8\\xb8')}\n",
      "{'ى', ')', '0', '4', 'ة', 'ح', ':', 'ف', 'ي', 'ع', '9', '،', '\"', '/', 'ب', 'ء', 'ٌ', 'ز', \"'\", '–', 'و', 'إ', 'َ', '3', '(', 'ٍ', '»', 'ا', 'س', 'ش', '}', '5', 'ض', '-', ',', 'ث', '{', 'م', 'ص', '8', 'ت', 'ق', 'خ', '\\u200f', 'ً', 'ه', '1', '[', '؟', '2', 'غ', 'آ', 'ُ', '7', 'ّ', '~', '6', '`', 'ؤ', 'ن', 'ل', '!', 'د', '.', '؛', 'ج', ';', ']', 'ط', ' ', 'ِ', '«', 'ر', 'ك', 'ئ', 'ذ', 'ْ', '\\n', 'ظ', '*', 'أ'}\n",
      "81\n",
      "{'ق', 'ى', '0', 'د', '4', 'خ', 'ة', 'ح', '\\u200f', 'ً', 'ف', 'ه', '1', '–', 'ي', '2', 'غ', 'آ', 'و', 'ج', 'ع', 'ُ', 'إ', 'َ', '3', 'ٍ', 'ط', 'ت', '9', 'ا', 'ّ', '7', ' ', '»', '~', 'ِ', 'س', 'ش', '6', '«', '`', '5', 'ر', 'ض', 'ك', 'ئ', 'ث', '/', 'ب', 'ء', 'ذ', 'ْ', 'ؤ', 'م', 'ٌ', 'ص', 'ن', '\\n', 'ل', 'ز', '8', 'ظ', '*', 'أ'}\n",
      "64\n",
      "{')', '!', ':', '؟', '[', \"'\", '.', '؛', ';', '(', ']', '،', '}', '\"', '-', ',', '{'}\n",
      "17\n",
      "{'ق', 'ى', 'د', 'ة', 'خ', 'ح', 'ً', 'ف', 'ه', 'ي', 'آ', 'غ', 'و', 'ج', 'ع', 'ُ', 'إ', 'َ', 'ت', 'ٍ', 'ط', 'ا', 'ّ', ' ', 'ِ', 'س', 'ش', 'ر', 'ض', 'ك', 'ئ', 'ث', 'ب', 'ء', 'ذ', 'ؤ', 'ْ', 'م', 'ٌ', 'ص', 'ن', 'ل', 'ز', 'ظ', 'أ'}\n",
      "45\n",
      "{'0', '4', '\\u200f', '1', '2', '9', '7', '~', '6', '`', '/', '–', '3', '»', '«', '5', '\\n', '8', '*'}\n",
      "19\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "class ArabicDiacritics(Enum):\n",
    "    SHADDA_FATHATAN = '\\u0651\\u064b'\n",
    "    SHADDA_DAMMATAN = '\\u0651\\u064c'\n",
    "    SHADDA_KASRATAN = '\\u0651\\u064d'\n",
    "    SHADDA_FATHA = '\\u0651\\u064e'\n",
    "    SHADDA_DAMMA = '\\u0651\\u064f'\n",
    "    SHADDA_KASRA = '\\u0651\\u0650'\n",
    "    SHADDA_SUKUN = '\\u0651\\u0652'\n",
    "    SHADDA = '\\u0651'\n",
    "    FATHATAN = '\\u064b'\n",
    "    DAMMATAN = '\\u064c'\n",
    "    KASRATAN = '\\u064d'\n",
    "    FATHA = '\\u064e'\n",
    "    DAMMA = '\\u064f'\n",
    "    KASRA = '\\u0650'\n",
    "    SUKUN = '\\u0652'\n",
    "\n",
    "class ArabicCharacters(Enum):\n",
    "    HAMZA = u'\\u0621'\n",
    "    ALEF_MADDA = u'\\u0622'\n",
    "    ALEF_HAMZA_ABOVE = u'\\u0623'\n",
    "    WAW_HAMZA = u'\\u0624'\n",
    "    ALEF_HAMZA_BELOW = u'\\u0625'\n",
    "    YEH_HAMZA = u'\\u0626'\n",
    "    ALEF = u'\\u0627'\n",
    "    BEH = u'\\u0628'\n",
    "    TEH_MARBUTA = u'\\u0629'\n",
    "    TEH = u'\\u062a'\n",
    "    THEH = u'\\u062b'\n",
    "    JEEM = u'\\u062c'\n",
    "    HAH = u'\\u062d'\n",
    "    KHAH = u'\\u062e'\n",
    "    DAL = u'\\u062f'\n",
    "    THAL = u'\\u0630'\n",
    "    REH = u'\\u0631'\n",
    "    ZAIN = u'\\u0632'\n",
    "    SEEN = u'\\u0633'\n",
    "    SHEEN = u'\\u0634'\n",
    "    SAD = u'\\u0635'\n",
    "    DAD = u'\\u0636'\n",
    "    TAH = u'\\u0637'\n",
    "    ZAH = u'\\u0638'\n",
    "    AIN = u'\\u0639'\n",
    "    GHAIN = u'\\u063a'\n",
    "    TATWEEL = u'\\u0640'\n",
    "    FEH = u'\\u0641'\n",
    "    QAF = u'\\u0642'\n",
    "    KAF = u'\\u0643'\n",
    "    LAM = u'\\u0644'\n",
    "    MEEM = u'\\u0645'\n",
    "    NOON = u'\\u0646'\n",
    "    HEH = u'\\u0647'\n",
    "    WAW = u'\\u0648'\n",
    "    ALEF_MAKSURA = u'\\u0649'\n",
    "    YEH = u'\\u064a'\n",
    "\n",
    "class Preprocessor:\n",
    "\n",
    "    def __init__(self):\n",
    "        f = FileReader()\n",
    "\n",
    "\n",
    "    # clean the arabic text from any non arabic characters and store the clean data inside an new output file\n",
    "    def clean_data(self, data,output_file):\n",
    "        tokens = tokenize(data, conditions=is_arabicrange)\n",
    "        cleaned_data = u\" \".join(tokens)\n",
    "        f.write_file(output_file, cleaned_data)\n",
    "\n",
    "\n",
    "    # remove diacritics from arabic text and store the new data inside a new file\n",
    "    def remove_diacritics(self, data, output_file):\n",
    "        data_with_diactrics = strip_tashkeel(data)\n",
    "        f.write_file(output_file, data_with_diactrics)\n",
    "\n",
    "\n",
    "    # remove all punctuation characters and store the result inside the output file\n",
    "    def remove_tarkeem(self, data, output_file):\n",
    "        arabic_punctuation = ['،', '٪', '؛', '؟', 'ـ']\n",
    "        english_punctuation = [',', '.', '%', ':', ';', '?', '!', '-', '_', \"'\", '\"', '(', ')', '[', ']', '{', '}']\n",
    "        data_without_tarkeem = \"\"\n",
    "        for character in data:\n",
    "            if character not in arabic_punctuation and character not in english_punctuation:\n",
    "                data_without_tarkeem += character\n",
    "        f.write_file(output_file, data_without_tarkeem)\n",
    "\n",
    "    def separate_diacritics(self, arabic_text):\n",
    "        diacritics_list = []\n",
    "        # internal function to replace diacritics with empty strings for the letters\n",
    "        def diacritics_replacement(match):\n",
    "            diacritic = match.group(2)\n",
    "            diacritics_list.append(diacritic)\n",
    "            return match.group(1) \n",
    "        \n",
    "        # Define a pattern to match Arabic diacritics and shadda using the enum values\n",
    "        diacritics_pattern = re.compile(\"([\" + \"\".join([re.escape(character.value) for character in ArabicCharacters]) + \" ])\" + \"([\" + \"\".join([re.escape(diacritic.value) for diacritic in ArabicDiacritics]) + \"]*)|(.)\")\n",
    "\n",
    "        # Remove diacritics and shadda using the pattern and store them in the list\n",
    "        result_text = re.sub(diacritics_pattern, diacritics_replacement, arabic_text)\n",
    "\n",
    "        return result_text, diacritics_list\n",
    "    \n",
    "\n",
    "P1 = Preprocessor()\n",
    "arabic_text = \"الذِّمِّيِّ أَنْ يَحْتَسِبَ عَلَى الْمُسْلِم\"\n",
    "result, diacritics = P1.separate_diacritics(arabic_text)\n",
    "print(result)\n",
    "print(diacritics)\n",
    "\n",
    "for diacritic_value in diacritics:\n",
    "    if diacritic_value in [diacritic.value for diacritic in ArabicDiacritics]:\n",
    "        for diacritic in ArabicDiacritics:\n",
    "            if diacritic.value == diacritic_value:\n",
    "                print(f\"Extracted Diacritic: {diacritic.name}\")\n",
    "    else:\n",
    "        print(f\"Extracted Diacritic: No Diacritic\")\n",
    "\n",
    "f = FileReader()\n",
    "data1 = f.open_file(\"train.txt\")\n",
    "P1.remove_tarkeem(data1, \"no_tarkeem.txt\")\n",
    "\n",
    "data2 = f.open_file(\"no_tarkeem.txt\")\n",
    "P1.clean_data(data2, \"clean_data.txt\")\n",
    "\n",
    "data3 = f.open_file(\"clean_data.txt\")\n",
    "P1.remove_diacritics(data3, \"no_diacritics.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
