{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26146,"status":"ok","timestamp":1704021222302,"user":{"displayName":"Ahmed Maher","userId":"03041856425174770196"},"user_tz":-120},"id":"TrghCaBgiVFz","outputId":"5fa33d73-2b31-40d7-9f34-c87b708e368a"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-31 17:25:44.708910: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-31 17:25:44.708968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-31 17:25:44.710988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-31 17:25:44.717898: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-31 17:25:45.646959: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import os\n","from enum import Enum\n","import re\n","import numpy as np\n","from pyarabic.araby import separate, tokenize, is_arabicrange, strip_tashkeel, strip_tatweel\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","import tensorflow as tf\n","from keras_preprocessing.sequence import pad_sequences\n","from keras.models import Sequential,load_model, Model\n","from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, CategoryEncoding, Bidirectional, Input, Dropout, TimeDistributed\n","from keras.initializers import glorot_normal\n","from gensim.models import Word2Vec\n","\n","from chars_enums import *\n","from file_reader import FileReader\n","from preprocessor import Preprocessor"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":266,"status":"ok","timestamp":1704021229625,"user":{"displayName":"Ahmed Maher","userId":"03041856425174770196"},"user_tz":-120},"id":"j_t3Me8ZiVF4","outputId":"4a147dc0-e87a-407e-f9b3-e411f20f4395"},"outputs":[{"name":"stdout","output_type":"stream","text":["الذمي أن يحتسب على المسلم\n","['', '', 'ِّ', 'ِّ', 'ِّ', '', 'َ', 'ْ', '', 'َ', 'ْ', 'َ', 'ِ', 'َ', '', 'َ', 'َ', '', '', '', 'ْ', 'ُ', 'ْ', 'ِ', '']\n","Extracted Diacritic: No Diacritic\n","Extracted Diacritic: No Diacritic\n","Extracted Diacritic: ARABIC_SHADDA_KASRA\n","Extracted Diacritic: ARABIC_SHADDA_KASRA\n","Extracted Diacritic: ARABIC_SHADDA_KASRA\n","Extracted Diacritic: No Diacritic\n","Extracted Diacritic: ARABIC_FATHA\n","Extracted Diacritic: ARABIC_SUKUN\n","Extracted Diacritic: No Diacritic\n","Extracted Diacritic: ARABIC_FATHA\n","Extracted Diacritic: ARABIC_SUKUN\n","Extracted Diacritic: ARABIC_FATHA\n","Extracted Diacritic: ARABIC_KASRA\n","Extracted Diacritic: ARABIC_FATHA\n","Extracted Diacritic: No Diacritic\n","Extracted Diacritic: ARABIC_FATHA\n","Extracted Diacritic: ARABIC_FATHA\n","Extracted Diacritic: No Diacritic\n","Extracted Diacritic: No Diacritic\n","Extracted Diacritic: No Diacritic\n","Extracted Diacritic: ARABIC_SUKUN\n","Extracted Diacritic: ARABIC_DAMMA\n","Extracted Diacritic: ARABIC_SUKUN\n","Extracted Diacritic: ARABIC_KASRA\n","Extracted Diacritic: No Diacritic\n"]}],"source":["P1 = Preprocessor()\n","arabic_text = \"الذِّمِّيِّ أَنْ يَحْتَسِبَ عَلَى الْمُسْلِم\"\n","result, diacritics = P1.separate_diacritics(arabic_text)\n","print(result)\n","print(diacritics)\n","\n","for diacritic_value in diacritics:\n","    if diacritic_value in [diacritic.value.decode(\"utf-8\") for diacritic in ArabicDiacritics]:\n","        for diacritic in ArabicDiacritics:\n","            if diacritic.value.decode(\"utf-8\") == diacritic_value:\n","                print(f\"Extracted Diacritic: {diacritic.name}\")\n","    else:\n","        print(f\"Extracted Diacritic: No Diacritic\")"]},{"cell_type":"markdown","metadata":{"id":"-mymvLM4iVF5"},"source":["### Output one hot encoding\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704026895254,"user":{"displayName":"Ahmed Maher","userId":"03041856425174770196"},"user_tz":-120},"id":"l82QXtvUiVF6"},"outputs":[],"source":["def to_one_hot(ashkal, size):\n","    one_hot = []\n","    for diacritic in ashkal:\n","        coded = [0] * size\n","        if diacritic.encode('utf-8') in ArabicDiacritics_Mapping:\n","            coded[ArabicDiacritics_Mapping[diacritic.encode('utf-8')]] = 1\n","        one_hot.append(coded)\n","        \n","    return one_hot"]},{"cell_type":"markdown","metadata":{"id":"7PFE5350iVF8"},"source":["### Model Structure"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":270,"status":"ok","timestamp":1704021507294,"user":{"displayName":"Ahmed Maher","userId":"03041856425174770196"},"user_tz":-120},"id":"3UndMRQtiVF9"},"outputs":[],"source":["def create_model():\n","   arabic_chars = 36\n","   num_of_ashkaaal = 15\n","   max_word_length = 15\n","\n","   SelectedLSTM = LSTM\n","\n","   inputs = Input(shape=(max_word_length,))\n","\n","   embeddings = Embedding(input_dim=arabic_chars, output_dim=36)(inputs)\n","\n","   blstm1 = Bidirectional(SelectedLSTM(units=256, return_sequences=True))(embeddings)\n","   dropout1 = Dropout(0.5)(blstm1)\n","\n","   blstm2 = Bidirectional(SelectedLSTM(units=256, return_sequences=True))(dropout1)\n","   dropout2 = Dropout(0.5)(blstm2)\n","\n","   dense1 = TimeDistributed(Dense(units=512, activation='relu'))(dropout2)\n","\n","   dense2 = TimeDistributed(Dense(units=512, activation='relu'))(dense1)\n","\n","   output = TimeDistributed(Dense(units=num_of_ashkaaal, activation='softmax'))(dense2)\n","\n","   model = Model(inputs, output)\n","\n","   model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","   return model\n"]},{"cell_type":"markdown","metadata":{"id":"I7oUbjfoiVF-"},"source":["### Model Training"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1704021509270,"user":{"displayName":"Ahmed Maher","userId":"03041856425174770196"},"user_tz":-120},"id":"5alzAOKbiVF_"},"outputs":[],"source":["class TrainModel:\n","    def __init__(self,X_train, y_train, epochs, batch_size):\n","        self.X_train = X_train\n","        self.y_train = y_train\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","\n","    def train(self):\n","        model = create_model()\n","        predict = model.fit(self.X_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size)\n","        model.summary()\n","        return model\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fQ40AZ-GiVF_"},"source":["### Prepare data for training"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":155514,"status":"ok","timestamp":1704022360724,"user":{"displayName":"Ahmed Maher","userId":"03041856425174770196"},"user_tz":-120},"id":"_JkbM9QXiVGA","outputId":"f76a89a1-f4d4-4bab-b2ab-cc98e4071ef6"},"outputs":[{"name":"stdout","output_type":"stream","text":["2102068\n","2102068\n"]}],"source":["file_reader = FileReader()\n","\n","#data = file_reader.open_file(\"train.txt\")\n","\n","process = Preprocessor()\n","\n","#process.clean_data(data, \"only_arabic.txt\")\n","\n","#only_arabic = file_reader.open_file(\"only_arabic.txt\")\n","\n","#process.remove_tarkeem(only_arabic, \"no_tarkeem.txt\")\n","\n","no_tarkeem = file_reader.open_file(\"no_tarkeem.txt\")\n","\n","tokens = tokenize(no_tarkeem)\n","\n","letters_tokens = []\n","diacritics_tokens = []\n","for token in tokens:\n","  letters, diacritic = process.separate_diacritics(token)\n","  letters_tokens.append(letters)\n","  diacritics_tokens.append(diacritic)\n","\n","\n","print(len(letters_tokens))\n","print(len(diacritics_tokens))\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{b'\\xd8\\xa1': 0, b'\\xd8\\xa2': 1, b'\\xd8\\xa3': 2, b'\\xd8\\xa4': 3, b'\\xd8\\xa5': 4, b'\\xd8\\xa6': 5, b'\\xd8\\xa7': 6, b'\\xd8\\xa8': 7, b'\\xd8\\xa9': 8, b'\\xd8\\xaa': 9, b'\\xd8\\xab': 10, b'\\xd8\\xac': 11, b'\\xd8\\xad': 12, b'\\xd8\\xae': 13, b'\\xd8\\xaf': 14, b'\\xd8\\xb0': 15, b'\\xd8\\xb1': 16, b'\\xd8\\xb2': 17, b'\\xd8\\xb3': 18, b'\\xd8\\xb4': 19, b'\\xd8\\xb5': 20, b'\\xd8\\xb6': 21, b'\\xd8\\xb7': 22, b'\\xd8\\xb8': 23, b'\\xd8\\xb9': 24, b'\\xd8\\xba': 25, b'\\xd9\\x81': 26, b'\\xd9\\x82': 27, b'\\xd9\\x83': 28, b'\\xd9\\x84': 29, b'\\xd9\\x85': 30, b'\\xd9\\x86': 31, b'\\xd9\\x87': 32, b'\\xd9\\x88': 33, b'\\xd9\\x89': 34, b'\\xd9\\x8a': 35}\n","{b'\\xd9\\x91\\xd9\\x8b': 0, b'\\xd9\\x91\\xd9\\x8c': 1, b'\\xd9\\x91\\xd9\\x8d': 2, b'\\xd9\\x91\\xd9\\x8e': 3, b'\\xd9\\x91\\xd9\\x8f': 4, b'\\xd9\\x91\\xd9\\x90': 5, b'\\xd9\\x91\\xd9\\x92': 6, b'\\xd9\\x8b': 7, b'\\xd9\\x8c': 8, b'\\xd9\\x8d': 9, b'\\xd9\\x8e': 10, b'\\xd9\\x8f': 11, b'\\xd9\\x90': 12, b'\\xd9\\x91': 13, b'\\xd9\\x92': 14}\n","[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]]\n","[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n","[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]]\n"]}],"source":["print(ArabicCharacters_Mapping)\n","print(ArabicDiacritics_Mapping)\n","\n","output_hot_encoded = []\n","for ashkaal in diacritics_tokens[0:2]:\n","    coded = to_one_hot(ashkaal, 15)\n","    output_hot_encoded.append(coded)\n","    print(coded)\n","print(output_hot_encoded)"]},{"cell_type":"markdown","metadata":{"id":"c87loSE7pscM"},"source":["### prepare X_train"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262548,"status":"ok","timestamp":1704024430733,"user":{"displayName":"Ahmed Maher","userId":"03041856425174770196"},"user_tz":-120},"id":"1rt3GPHipwsV","outputId":"f1710fb8-d982-497e-9f84-b9454655dd58"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[27 33 29 ... -1 -1 -1]\n"," [ 2 33 -1 ... -1 -1 -1]\n"," [27 22 24 ... -1 -1 -1]\n"," ...\n"," [16 12 30 ... -1 -1 -1]\n"," [ 6 29 29 ... -1 -1 -1]\n"," [ 9 24  6 ... -1 -1 -1]]\n"]}],"source":["sequences = []\n","for word in letters_tokens[:100000]:\n","  newWord = []\n","  for letter in word:\n","    newWord.append(ArabicCharacters_Mapping[letter.encode('utf-8')])\n","  sequences.append(newWord)\n","\n","padded_input = pad_sequences(sequences, maxlen=15, padding='post', truncating='post', value=-1)\n","print(padded_input)"]},{"cell_type":"markdown","metadata":{"id":"vgzBmi8exluL"},"source":["### prepare y_train"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9562,"status":"ok","timestamp":1704026911728,"user":{"displayName":"Ahmed Maher","userId":"03041856425174770196"},"user_tz":-120},"id":"7SQx_iGexmGw","outputId":"0c81dfef-2b97-4b07-942d-e81a339678ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 1]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 1]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," ...\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 1 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]]\n"]}],"source":["output_hot_encoded = []\n","for ashkaal in diacritics_tokens[:100000]:\n","    coded = to_one_hot(ashkaal, 15)\n","    output_hot_encoded.append(coded)\n","\n","padded_output = pad_sequences(output_hot_encoded, maxlen=15, padding='post', truncating='post', value=[0] * 15)\n","print(padded_output)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1704026915221,"user":{"displayName":"Ahmed Maher","userId":"03041856425174770196"},"user_tz":-120},"id":"4VPY9hLK3Hc6","outputId":"3b78aa54-911d-4b4f-c71b-adfddf272e90"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[27 33 29 32 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"," [ 2 33 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"," [27 22 24 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"," [ 6 29  2 33 29 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"," [35 14 32 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"," [ 4 29 13 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"," [27  6 29 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"," [ 6 29 17 16 28 19 35 -1 -1 -1 -1 -1 -1 -1 -1]\n"," [ 6  7 31 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"," [24 16 26  8 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]] <class 'numpy.ndarray'>\n","[[[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 1]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 1]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," ...\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 1]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]] <class 'numpy.ndarray'>\n"]}],"source":["print(padded_input[:10],type(padded_input))\n","print(padded_output[:10],type(padded_output))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":358},"executionInfo":{"elapsed":1413,"status":"error","timestamp":1704026819049,"user":{"displayName":"Ahmed Maher","userId":"03041856425174770196"},"user_tz":-120},"id":"iRa1Io_WiVGC","outputId":"08dcb067-2c95-4155-a8ff-ac49a53d265e"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-31 17:27:40.104257: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-31 17:27:40.134035: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-31 17:27:40.134693: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-31 17:27:40.140180: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-31 17:27:40.141005: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-31 17:27:40.141814: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-31 17:27:40.562670: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-31 17:27:40.563208: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-31 17:27:40.563224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n","2023-12-31 17:27:40.563703: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-31 17:27:40.563741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4093 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["2023-12-31 17:27:46.508636: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n","2023-12-31 17:27:49.477329: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fc7f6645c10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-12-31 17:27:49.477376: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n","2023-12-31 17:27:49.483711: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1704036469.768265   41582 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["100/100 [==============================] - 14s 50ms/step - loss: 0.3537\n","Epoch 2/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.2985\n","Epoch 3/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.2733\n","Epoch 4/50\n","100/100 [==============================] - 3s 29ms/step - loss: 0.2392\n","Epoch 5/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.2097\n","Epoch 6/50\n","100/100 [==============================] - 3s 28ms/step - loss: 0.1883\n","Epoch 7/50\n","100/100 [==============================] - 3s 28ms/step - loss: 0.1720\n","Epoch 8/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.1598\n","Epoch 9/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.1496\n","Epoch 10/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.1420\n","Epoch 11/50\n","100/100 [==============================] - 3s 34ms/step - loss: 0.1345\n","Epoch 12/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.1283\n","Epoch 13/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.1223\n","Epoch 14/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.1155\n","Epoch 15/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.1125\n","Epoch 16/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.1061\n","Epoch 17/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.1030\n","Epoch 18/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0993\n","Epoch 19/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0945\n","Epoch 20/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0916\n","Epoch 21/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0885\n","Epoch 22/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0854\n","Epoch 23/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0831\n","Epoch 24/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0796\n","Epoch 25/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0775\n","Epoch 26/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0735\n","Epoch 27/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0726\n","Epoch 28/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0702\n","Epoch 29/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0669\n","Epoch 30/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0649\n","Epoch 31/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0636\n","Epoch 32/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0619\n","Epoch 33/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0590\n","Epoch 34/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0576\n","Epoch 35/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0567\n","Epoch 36/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0545\n","Epoch 37/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0533\n","Epoch 38/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0510\n","Epoch 39/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0513\n","Epoch 40/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0499\n","Epoch 41/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0482\n","Epoch 42/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0462\n","Epoch 43/50\n","100/100 [==============================] - 3s 32ms/step - loss: 0.0456\n","Epoch 44/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0443\n","Epoch 45/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0432\n","Epoch 46/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0422\n","Epoch 47/50\n","100/100 [==============================] - 3s 30ms/step - loss: 0.0417\n","Epoch 48/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0403\n","Epoch 49/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0410\n","Epoch 50/50\n","100/100 [==============================] - 3s 31ms/step - loss: 0.0394\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 15)]              0         \n","                                                                 \n"," embedding (Embedding)       (None, 15, 36)            1296      \n","                                                                 \n"," bidirectional (Bidirection  (None, 15, 512)           600064    \n"," al)                                                             \n","                                                                 \n"," dropout (Dropout)           (None, 15, 512)           0         \n","                                                                 \n"," bidirectional_1 (Bidirecti  (None, 15, 512)           1574912   \n"," onal)                                                           \n","                                                                 \n"," dropout_1 (Dropout)         (None, 15, 512)           0         \n","                                                                 \n"," time_distributed (TimeDist  (None, 15, 512)           262656    \n"," ributed)                                                        \n","                                                                 \n"," time_distributed_1 (TimeDi  (None, 15, 512)           262656    \n"," stributed)                                                      \n","                                                                 \n"," time_distributed_2 (TimeDi  (None, 15, 15)            7695      \n"," stributed)                                                      \n","                                                                 \n","=================================================================\n","Total params: 2709279 (10.34 MB)\n","Trainable params: 2709279 (10.34 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["\n","X_train = padded_input[:10000]\n","\n","y_train = padded_output[:10000]\n","\n","\n","\n","epochs = 50\n","\n","batch_size = 100\n","\n","train_model = TrainModel(X_train, y_train, epochs, batch_size)\n","\n","trained_model = train_model.train()\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 49ms/step\n","ذَهْبٍ عَلَيَّ اَلَّىْ اُلْشَّاْطِيِّءُ ثُمَّ لَعِبٍ اَلْكِرَّةِ \n"]}],"source":["letters = \"ذهب علي الى الشاطيء ثم لعب الكرة\"\n","tokens = tokenize(letters)\n","sequences = []\n","for word in tokens:\n","  newWord = []\n","  for letter in word:\n","    newWord.append(ArabicCharacters_Mapping[letter.encode('utf-8')])\n","  sequences.append(newWord)\n","\n","padded_input = pad_sequences(sequences, maxlen=15, padding='post', truncating='post', value=-1)\n","\n","diacritics = trained_model.predict(padded_input)\n","\n","results = \"\"\n","\n","for i in range(0, len(tokens)):\n","    letter_list = tokens[i]\n","    diacritic_list = diacritics[i]\n","    for j in range(0, len(letter_list)):\n","        results += letter_list[j]\n","        index = np.argmax(diacritic_list[j])\n","        results += ArabicDiacritics_RevMapping[index].decode('utf-8')\n","    results += \" \"\n","\n","print(results)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
